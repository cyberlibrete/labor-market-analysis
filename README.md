# Анализ рынка труда
Аналитическая система для сбора, хранения, обработки и визуализации данных о рынке труда из открытых источников: HH.ru, SuperJob и других доступных API.

## О проекте
Цель проекта — создать универсальный инструментарий для исследования рынка труда, анализа востребованных компетенций, уровня зарплат, динамики спроса, а также формирования аналитических отчётов и интерактивных дашбордов.
Система строится как модульный open-source-проект, где каждый компонент выполняет строго определённую функцию:
- Сбор данных из разных API сайтов с вакансиями.
- Очистка и нормализация информации.
- Загрузка в локальное хранилище на PostgreSQL.
- Аналитика и расчёт показателей (skills-demand, salary ranges, seniority mapping и др.).
- Визуализация результатов в виде графиков и дашборда.

## Основные задачи проекта
- Автоматизировать сбор вакансий с нескольких платформ.
- Создать единую структуру данных (универсальную модель вакансий).
- Обеспечить хранение данных в PostgreSQL с оптимизированными схемами.
- Реализовать модуль анализа потребностей работодателей.
- Разработать дашборд для удобного анализа динамики рынка труда.

## Архитектура проекта
Проект разделён на четыре ключевых слоя:

1. Data Collection (ETL-сборщик)
- Python-скрипты для работы с API HH, SuperJob и других источников.
- Механизм нормализации данных (приведение к единому формату).

2. Storage Layer (PostgreSQL)
- Локальная база данных.
- Схема таблиц вакансий, работодателей, навыков и статистических показателей.

3. Analytics Layer
- Загрузка данных из PostgreSQL.
- Подсчёт KPI: - популярные навыки;
- уровни зарплат;
- распределение по профессиям;
- динамика публикаций;
- кластеризация вакансий (опционально).

4. Visualization Layer
- Интерактивные графики.
- Возможность создания полноценного дашборда (например, Streamlit / Dash / Jupyter).

## Технологии
- Python 3.11+
- PostgreSQL 15+
- requests / aiohttp для API
- pandas, SQLAlchemy, psycopg2 / asyncpg
- matplotlib / plotly
- Docker (опционально)

## Планы разработки
- Добавить поддержку асинхронной выгрузки вакансий.
- Реализовать систему декоративных метрик (например, индекс «востребованности профессии»).
- Добавить поддержку машинного обучения.
- Построить веб-дашборд.

## Структура файлов проекта
Ниже структура, оптимальная для Python-проекта с ETL + аналитикой:

```bash
labor-market-analytics/
│
├── README.md
├── pyproject.toml                # poetry или setuptools
├── requirements.txt              # зависимости (если без poetry)
├── .env.example                  # пример конфигурации БД / API
├── .gitignore
│
├── data/
│   ├── raw/                      # исходные выгрузки с API
│   ├── processed/                # очищенные и нормализованные данные
│   └── examples/                 # пример данных для демонстраций
│
├── src/
│   ├── collectors/               # сборщики данных
│   │   ├── hh_api.py
│   │   ├── superjob_api.py
│   │   └── base_client.py
│   │
│   ├── cleaning/                 # очистка + нормализация
│   │   ├── normalize.py
│   │   └── mapping.py
│   │
│   ├── db/
│   │   ├── models/               # SQLAlchemy модели
│   │   │   ├── vacancy.py
│   │   │   ├── employer.py
│   │   │   └── skill.py
│   │   ├── schema.sql            # SQL схема
│   │   └── loader.py             # загрузка данных в PostgreSQL
│   │
│   ├── analytics/
│   │   ├── kpi.py                # ключевые показатели
│   │   ├── trends.py             # динамика
│   │   └── skills.py             # анализ навыков
│   │
│   ├── visualization/
│   │   ├── charts.py
│   │   └── dashboard.py
│   │
│   └── utils/
│       ├── config.py
│       ├── logging.py
│       └── helpers.py
│
├── notebooks/
│   ├── overview.ipynb            # обзор данных
│   └── analytics.ipynb           # аналитические эксперименты
│
└── docs/
    ├── architecture.md
    ├── api_spec.md
    └── db_schema.md
```

## Как начать работу
1. Клонировать репозиторий.
2. Скопировать .env.example в .env и вписать токены API + настройки БД.
3. Установить зависимости: `pip install -r requirements.txt`
4. Применить SQL-схему (src/db/schema.sql).
5. Запустить сборщик данных: `python src/collectors/hh_api.py`
6. Запустить анализ: `python src/analytics/kpi.py`

